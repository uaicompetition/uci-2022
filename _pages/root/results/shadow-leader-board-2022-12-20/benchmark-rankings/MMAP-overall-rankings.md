---
title: "MMAP overall Rankings"
date: 2022-12-20
permalink: /results/shadow-leader-board-2022-12-20/benchmark-rankings/MMAP-overall-rankings
---



The results below are organized as follows:
- each table displays the cumulative results for the given benchmark under different time limits
- table values are average normalized scores for only problems from the given benchmark evaluated as outlined in [Evaluation Criteria](https://uaicompetition.github.io/uci-2022/results/evaluation-criteria/)
- clicking on a solver name links to its results on individual problem instances


|                                 Solver                                  | 20sec | 1200sec | 3600sec |
| ----------------------------------------------------------------------- | ----: | ------: | ------: |
| [toulbar2-vns-mmap](../solver-scores/toulbar2-vns-mmap-scores.md)       |  70.5 |    72.2 |    72.3 |
| [toulbar2-ipr-mmap](../solver-scores/toulbar2-ipr-mmap-scores.md)       |  67.8 |    72.7 |    73.4 |
| [daoopt-mmap](../solver-scores/daoopt-mmap-scores.md)                   |  68.5 |    72.1 |    71.8 |
| [toulbar2-vacint-mmap](../solver-scores/toulbar2-vacint-mmap-scores.md) |  69.0 |    71.4 |    71.5 |
| [daoopt-lh-mmap](../solver-scores/daoopt-lh-mmap-scores.md)             |  17.5 |    36.1 |    47.2 |
| [uai14-mmap](../solver-scores/uai14-mmap-scores.md)                     |  28.9 |    33.8 |    35.4 |
| [lbp-mmap](../solver-scores/lbp-mmap-scores.md)                         |  28.3 |    29.4 |    29.6 |
| [merlin-mmap](../solver-scores/merlin-mmap-scores.md)                   |  14.5 |    15.1 |    20.2 |
| [baseline](../solver-scores/baseline-scores.md)                         |   0.0 |     0.0 |     0.0 |

